TASK: ClassificationTask

DATASET:
  FEATURE_DATASET:
    TYPE: Vivqav2FeatureDataset
    BATCH_SIZE: 16
    WORKERS: 0
    FEATURE_PATH:
      FEATURES: features\vinvl_vinvl
      SCENE_TEXT: null
      IMAGE: data/vivqa_v2/images
  VOCAB:
    TYPE: VQAv2ClassificationVocab
    TOKENIZER: null
    MIN_FREQ: 1
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
    BOS_TOKEN: <bos>
    EOS_TOKEN: <eos>
    PAD_TOKEN: <pad>
    UNK_TOKEN: <unk>
    IMG_TOKEN: <img>
    FEAT_TOKEN: <feat>
    BOX_TOKEN: <box>
    QUESTION_TOKEN: <question>
    ANSWER_TOKEN: <answer>
    JSON_PATH:
      TRAIN: data/vivqa_v2/vivqa_v2_train.json
      DEV: data/vivqa_v2/vivqa_v2_dev.json
      TEST: data/vivqa_v2/vivqa_v2_test.json
  JSON_PATH:
    TRAIN: data/vivqa_v2/vivqa_v2_train.json
    DEV: data/vivqa_v2/vivqa_v2_dev.json
    TEST: data/vivqa_v2/vivqa_v2_test.json

TRAINING:
  CHECKPOINT_PATH: saved_models
  LEARNING_RATE: 0.002
  WARMUP: 10000
  SCORE: CIDEr
  GET_SCORES: True
  TRAINING_BEAM_SIZE: 5
  EVALUATING_BEAM_SIZE: 3
  PATIENCE: 5
  VERBOSE_SCORES:
    - CIDEr
    - BLEU
    - ROUGE
    - Accuracy
    - F1
    - Precision
    - Recall
  
MODEL:
  ARCHITECTURE: PhrasalMCAN
  NAME: mcan_phrasal_vivqav2_2
  DEVICE: cuda
  D_MODEL: 512
  
  VISION_EMBEDDING:
    ARCHITECTURE: FeatureEmbedding
    D_FEATURE: 2048
    D_MODEL: 512
    DROPOUT: 0.1
    
  TEXT_EMBEDDING:
    ARCHITECTURE: LSTMTextEmbedding
    D_MODEL: 512
    D_EMBEDDING: 300
    DROPOUT: 0.1
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
    
  # Phrasal Self-Encoder: processes Vietnamese text with phrasal attention
  SELF_ENCODER:
    ARCHITECTURE: PhrasalEncoder
    D_MODEL: 512
    LAYERS: 3
    SELF_ATTENTION:
      ARCHITECTURE: PhrasalScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: 0.1
      # Phrasal-specific parameters
      LAMBDA_INIT: 1.0  # Initial value for learnable lambda
      USE_COTEXT_GATE: True  # Enable Co-Text gated fusion
      
  # Phrasal Guided Encoder: cross-modal attention with phrasal awareness
  GUIDED_ENCODER:
    ARCHITECTURE: PhrasalGuidedAttentionEncoder
    D_MODEL: 512
    LAYERS: 3
    SELF_ATTENTION:
      ARCHITECTURE: PhrasalScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: 0.1
      LAMBDA_INIT: 1.0
      USE_COTEXT_GATE: True
    GUIDED_ATTENTION:
      ARCHITECTURE: PhrasalScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: 0.1
      LAMBDA_INIT: 1.0
      USE_COTEXT_GATE: True
      
  VISION_ATTR_REDUCE:
    D_MODEL: 512
    DROPOUT: 0.1
    
  TEXT_ATTR_REDUCE:
    D_MODEL: 512
    DROPOUT: 0.1
